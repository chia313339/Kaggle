---
title: "Mercari Price Suggestion Challenge"
author: oooooooh!
output:
  word_document: default
  html_notebook: default
  pdf_document: default
---

# Overview

Competition URL：https://www.kaggle.com/c/mercari-price-suggestion-challenge/kernels 

時程表：

* February 7, 2018 - Entry deadline. You must accept the competition rules before this date in order to compete.
* February 7, 2018 - Team Merger deadline. This is the last day participants may join or merge teams.
* February 14, 2018 - Final submission deadline. This is the last day participants are allowed to modify Kernels, submit to competition, and to select the Kernel version for Stage 2. After this date, all the Kernels versions are recorded and will be re-run based on the selections.
* February 15, 2018 - Stage 2 evaluation period starts. Sit back and watch the leaderboard.
* February 21, 2018 - Stage 2 ends. Final results announced.


# Exploratory Data Analysis (EDA)

```{r echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
# 載入所需的套件
library(data.table) # Loading data
library(RColorBrewer) # wordcloud
library(wordcloud) # wordcloud
library(ggplot2) # plot
library(stringr) 

```

將train.tsv資料載入，因為沒加encoding在windows上category_name會出現亂碼(mac上還沒試過)，所以下此語法：

```{r}
# fread是專門針對大量資料的語言，可以快速讀取百萬筆資料，sep = '\t'因為資料是用大空格分隔。
train<-fread(file = '~/R/K/train.tsv', sep = '\t', header = TRUE,encoding = 'UTF-8')
```

接下來可以進行簡單的資料觀察

```{r}
# 觀察前5筆資料
head(train,5)
```

```{r}
# 欄位探勘
str(train)
```

```{r}
# 觀察各個欄位敘述統計
summary(train)
```

從提供的Overview可以知道欄位定義如下：

* train_id or test_id - the id of the listing
* name - the title of the listing. Note that we have cleaned the data to remove text that look like prices (e.g. $20) to avoid leakage. These removed prices are represented as [rm]
* item_condition_id - the condition of the items provided by the seller
* category_name - category of the listing
* brand_name
* price - the price that the item was sold for. This is the target variable that you will predict. The unit is USD. This column doesn't exist in test.tsv since that is what you will predict.
* shipping - 1 if shipping fee is paid by seller and 0 by buyer
* item_description - the full description of the item. Note that we have cleaned the data to remove text that look like prices (e.g. $20) to avoid leakage. These removed prices are represented as [rm]

模型為從商品的其他資訊，推測應變數價格price。首先觀察應變數資料：

```{r}
# 觀察price資料分布
hist(train$price, main='Histogram of price')
```

資料嚴重右偏，所以用log(x+1)修正資料，想辦法讓資料偏向常態一點。

```{r}
# 取log(price+1)
hist(log(train$price+1), main='Histogram of log  price + 1')
```

資料看起來正常一點了，後面會讓應變數做轉換，提高預測準確率。接下來我們來對其他欄位進行探勘。

## train_id

沒意義的東西就不看了。

## item_condition_id

賣方提供商品的狀況，因為沒有know how，所以這邊只能當單純的factor去看它，一樣來統計看看。

```{r}
table(train$item_condition_id)
```

可以看到大部份的資料集中在1，5是最少的。

```{r warning=FALSE}
# Y連續X類別變數 用anova進行變異數分析
log_price = log(train$price+1)
aov.item_condition_id <- aov(log_price~ train$item_condition_id)
summary(aov.item_condition_id)
```

P-value小於0.05，95%的信心水準下有顯著相關，但不到0.01，這個變數對我們的價格似乎有些微影響。

## category_name 

這個欄位資料都是文字，並且分類用"/"符號分隔，每個間隔內容看起來是獨立的，這裡把他當成分類貼標來看，所以需要進行文字探勘將它做拆解。
```{r}
# 觀察此欄位內容
head(train$category_name,5)
```

```{r}
# 把所有貼標轉換成清單統計結果
category_list<-unlist(strsplit(train$category_name,'/'))
category_df<-as.data.frame(table(category_list))
head(category_df[order(category_df$Freq,decreasing = T),],10)
```

```{r warning=FALSE}
# 轉化文字雲看一下
wordcloud(category_df$category_list, category_df$Freq, min.freq =500, random.order = F, ordered.colors = F)

```

可以看到女性貼標數量真的很多，比例上來看也高於其他貼標，研判據有資料參考價值，我們來看如果轉成類別會有多少元素。

```{r}
# 計算有幾列
nrow(category_df)
```

一個950個變數如果要轉成factor可能會讓演算法跑不動，到時候可能要轉化稀疏矩陣才能進行分析，我們來看一個商品最多能有幾個貼標。

```{r}
# 計算欄位內"/"的最大值
max(str_count(train$category_name, "/"))
```

可以把每個商品後面加4個欄位，並且根據"/"分隔，將標籤放進去，但是這樣對最後建模沒有太大幫助，最後還是決定轉為950個欄位的稀疏矩陣，比較好對應變數建立模型。

## brand_name
```{r}
# 統計一下品牌
brand_name_df<-as.data.frame(table(train$brand_name))
head(brand_name_df[order(brand_name_df$Freq,decreasing = T),],10)
```


最多的果然是空戚，畢竟大多商品不是名牌也是很正常的，在來是PINK、Nike、Victoria's Secret，難怪女裝會這麼多不是沒有原因的，我們一樣來統計名牌的總數：

```{r}
nrow(brand_name_df)
```

高達4810種名牌，看來是大大小小的名牌都進來了，我們一樣預計將之轉為稀疏矩陣處理。

## shipping 

從說明來看似乎跟應變數沒有太大關係，但既然他給了，一定有他的原因，我們一樣做一下多變量分析看一下。

```{r}
table(train$shipping)
```

```{r warning=FALSE}
aov.shipping <- aov(log_price~ train$shipping)
summary(aov.shipping)
```

想不到居然有高度相關！我們來看一下統計圖型。

```{r}
plot(aov.shipping$model)
```

分布上來看確實有些差異在，此因子看來也是重要變數。

## item_description

這個欄位是對商品的敘述，沒有一定的文字結構，如果用文字探勘進行單字統計，可能會非常的發散，所以我們改用字數來決定這個特徵。

```{r}
# 抓幾筆來看一下
data.frame(item_description=train$item_description[1:5],nchar=nchar(train$item_description[1:5]))
```

```{r}
# 檢定字數與價格相關性
cor.test(train$price,nchar(train$item_description))
```

P-value < 0.05 顯著相關，看來商品描述的字數長度會影響我們的商品價格，為了更精確驗證我們的假設，改根據"單字數"進行統計。

```{r}
# 寫迴圈將單字數計算出來
nword_itdes<-NULL
for ( i in 1:length(train$item_description)){
  nword_itdes[i]<-length(unlist(strsplit(train$item_description[i],' ')))
}
```

```{r}
# 將統計結果列出來
data.frame(item_description=train$item_description[1:5],nword=nword_itdes[1:5])
```

```{r}
# 檢定單字數與價格相關性
cor.test(train$price,nword_itdes)
```

P-value < 0.05 顯著相關，符合我們的假設，後面會以"單字數"進行建模分析，雖然進行細部的文字探勘可以提高模型準確率，但工程浩大所以先到這裡。


## name

同上面的商品敘述一樣，我們將之轉為單字數統計：
```{r}
# 寫迴圈將單字數計算出來
nword_name<-NULL
for ( i in 1:length(train$name)){
  nword_name[i]<-length(unlist(strsplit(train$name[i],' ')))
}
```

```{r}
# 將統計結果列出來
data.frame(name=train$name[1:5],nword=nword_name[1:5])
```

```{r}
# 檢定單字數與價格相關性
cor.test(train$price,nword_name)
```

P-value < 0.05 顯著相關，看來商品名稱的長度與價格有顯著關係，後面也會以"單字數"進行建模分析。商品名稱的內容通常會影響著價格，但這樣要進行更細部的文字探勘，由於工程耗大所以我們先做到這樣。



# Data processing

從前面EDA來看，我們有了初步建模計劃：

* name：轉為單字數。
* item_condition_id：保留原本值。
* category_name：轉為稀疏矩陣，950個，並加上貼標數。
* brand_name：轉為稀疏矩陣，4810個。
* shipping：保留原本值。
* item_description：轉為單字數。

我們先來看看怎麼轉稀疏矩陣。

```{r}
# 共有950個貼標
length(unique(category_list))
```

```{r}
# 這是第一個物品的貼標內容
unlist(strsplit(train$category_name[1],'/'))
```

```{r}
# 將貼標清單對第一個貼標內容做mapping 因為太多A只顯示前10個
head(unique(category_list) %in% unlist(strsplit(train$category_name[1],'/')),10)
```

```{r}
# 轉化為numeric
head(as.numeric(unique(category_list) %in% unlist(strsplit(train$category_name[1],'/')),10))
```

如此一來我就們就可以將所有的貼標轉化為矩陣，進而放進去做演算。因為資料量太多，我們先抽出所需要的訓練資料及測試資料，以n筆資料抽驗試驗。我們把train的資料當成有限母體，對應變數進行敘述統計。

```{r}
# 價格敘述統計
summary(log(train$price+1))
var(log(train$price+1))
sd(log(train$price+1))
```

以95%的信心水準，\alpha	=0.05，區間估計值為：

$$ \bar{x} \pm z_{\alpha/2} \frac{\sigma}{\sqrt{n}} $$
令$E$為邊際誤差，則:

$$ E=z_{\alpha/2} \frac{\sigma}{\sqrt{n}} \Rightarrow n=\frac{z^2_{\alpha/2}\sigma^2}{E^2} $$

對應95%信心水準，$z_{0.025}=1.96$，假設$E$為$0.01$，n則為$21563.47$，我們取大概整數$22000$，表示有95%的信心水準，誤差大概$\pm 0.01$。

```{r}
# 抽樣實驗 取22000進行資料處理
n=22000
train_idx<-sample(seq_len(nrow(train)),n,replace = F)
train_data<-train[train_idx]
```

```{r warning=FALSE}
# name：轉單字字數
data_tmp<-NULL
for (i in 1:length(train_data$name)){
  data_tmp[i]<-length(unlist(strsplit(train_data$name[i],' ')))
}
train_data$name_num<-data_tmp
```
```{r}
# item_condition_id：保持不變
# category_name：轉為稀疏矩陣 先加上貼標數
data_tmp<-NULL
for (i in 1:length(train_data$category_name)){
  data_tmp[i]<-length(unlist(strsplit(train_data$category_name[i],'/')))
}
train_data$category_name_cnt<-data_tmp
```

```{r}
# category_name：轉為稀疏矩陣 950個貼標
data_tmp<-NULL
# 將950個貼標類別轉為list
category_list<-unique(unlist(strsplit(train$category_name,'/')))
# 讓每個商品貼標對應list 回傳TRUE/FALSE 在轉為1/0
for (i in 1:length(train_data$category_name)){
  data_tmp<-rbind(data_tmp,as.numeric(unique(category_list) %in% unlist(strsplit(train$category_name[i],'/'))))
}
train_data<-cbind(train_data,data_tmp)
```

由於品牌過多，要轉為4000多個稀疏矩陣實在強人所難，所以決定改變一下做法。這邊決定根據品牌數量統計，排出等級，越多商品的廠牌通常越熱門，我們的品牌等級就會越高，我們將品牌根據次數統計後如下。

```{r}
# 統計出每個品牌及數量
brand_name_df<-as.data.frame(table(train$brand_name))
head(brand_name_df[order(brand_name_df$Freq,decreasing = T),])
```

```{r}
# 計算出出現10次以內的品牌
head(brand_name_df[brand_name_df$Freq<10,])
nrow(brand_name_df[brand_name_df$Freq > 0 & brand_name_df$Freq < 10,])
```

最多的是無品牌，而品牌出現次數少於10的又有3055個，代表品牌大者非常大，直接從原始資料很難做，所以我們一樣取log進行轉換，再將之進行分檻。

```{r}
# 將沒有品牌的欄位拿掉
brand_name_df<-brand_name_df[!brand_name_df$Var1=='',]
```

```{r}
# 統計品牌數量log(x+1)
hist.bn<-hist(log(brand_name_df$Freq+1))
summary(log(brand_name_df$Freq+1))
```

我們根據直方圖的分檻，將品牌分為11個等級，我們看一下分檻的次數分別是多少：

```{r}
# 直方圖的分檻 一共有10個值
exp(seq_len(10))-1
```

```{r}
# 處理品牌等級
cut<-c(-Inf,exp(seq_len(10))-1,Inf)
brand_name_df$grade<-cut(brand_name_df$Freq,cut,label=c(seq(11)))
head(brand_name_df)
```

```{r}
# 整理一下 把資料合併進去 並讓空值=0
brand_name_df<-data.frame(brand_name=as.character(brand_name_df$Var1),brand_grade=as.numeric(brand_name_df$grade))
train_data<-merge(train_data, brand_name_df, by = 'brand_name',all.x = TRUE)
train_data$brand_grade[is.na(train_data$brand_grade)==T]='0'
```

最後剩一個要轉換，item_description：轉為單字數。

```{r}
# item_description：轉為單字
data_tmp<-NULL
for (i in 1:length(train_data$item_description)){
  data_tmp[i]<-length(unlist(strsplit(train_data$item_description[i],' ')))
}
train_data$item_description_num<-data_tmp
```

```{r}
# 
```
























